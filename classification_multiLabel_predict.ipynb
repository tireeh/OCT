{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T10:14:28.881841Z",
     "start_time": "2018-10-09T10:14:27.819436Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, pdb, cv2, random, traceback, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from pprint import pprint, pformat\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, namedtuple\n",
    "from sklearn.metrics import  roc_curve, auc\n",
    "\n",
    "from dataloaders.Classification_Image import OCT_image_classification, OCT_classification_persample, natural_keys\n",
    "from dataloaders.Image_transforms import Resize, Split_h, Normalize_divide, To_CHW    \n",
    "from sklearn import metrics\n",
    "\n",
    "from networks.classification.ResNet import ResNet34, ResNet50, ResNet101\n",
    "from networks.classification.ResNet_original import ResNet34_original, ResNet50_original, ResNet18_original\n",
    "from networks.classification.DenseNet_original import DenseNet121_original, DenseNet169_original, DenseNet201_original\n",
    "\n",
    "from utils import aic_fundus_lesion_classification\n",
    "\n",
    "def save_pickle(obj, save_path): \n",
    "    parent_path = os.path.dirname(save_path)  # get parent path\n",
    "    if not os.path.exists(parent_path):\n",
    "        os.makedirs(parent_path)\n",
    "    cPickle.dump(obj, open(save_path, \"wb\"), True)\n",
    "\n",
    "def load_pickle(pickle_path):\n",
    "    with open(pickle_path, 'rb') as fo:\n",
    "        pickle_dict = cPickle.load(fo)\n",
    "    return pickle_dict\n",
    "\n",
    "def load_model(model_config, num_classes, device, gpus):\n",
    "    model = globals()[model_config.network](model_config.net_config, num_classes)\n",
    "    print(\"Load %s\"%(model_config.checkpoint))\n",
    "    model.load_state_dict(torch.load(model_config.checkpoint))\n",
    "    if len(gpus) > 1:\n",
    "        model = nn.DataParallel(model, gpus)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_labels(label_root, label_dict = OrderedDict([(255, 0), (191, 1), (128, 2)]), num_samples=128):\n",
    "    total_labels = []\n",
    "    for label_sample_name in tqdm(sorted(os.listdir(label_root))):\n",
    "        sample_labels = np.zeros((num_samples, 3))\n",
    "        # sort the image dir in numerical ascend order\n",
    "        image_names = os.listdir(os.path.join(label_root, label_sample_name))\n",
    "        image_names.sort(key=natural_keys)\n",
    "        for i, image_name in enumerate(image_names):\n",
    "            label_image = cv2.imread(os.path.join(label_root, label_sample_name, image_name))[:,:,0]\n",
    "            for target_pixel in label_dict:\n",
    "                if target_pixel in label_image:\n",
    "                    sample_labels[i, label_dict[target_pixel]] = 1\n",
    "        total_labels.append(sample_labels)\n",
    "    return total_labels\n",
    "\n",
    "def predict_ensemble(models, inputs, device, last_activation=\"sigmoid\"):\n",
    "    \"\"\"predict single input from the data loader via multiple models\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.float()\n",
    "        inputs = inputs.to(device)\n",
    "        softmaxs = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            output = model(inputs)\n",
    "            if last_activation == \"sigmoid\":\n",
    "                softmax = torch.sigmoid(output).detach().cpu().numpy()\n",
    "            elif last_activation == \"softmax\":\n",
    "                softmax = F.softmax(output, dim=1).detach().cpu().numpy()\n",
    "            else:\n",
    "                raise(\"Unknown activation function in last layer: {}\".format(last_activation))\n",
    "            softmaxs.append(softmax)\n",
    "        ensemble = np.mean(softmaxs, 0)\n",
    "    return ensemble\n",
    "\n",
    "def main(main_models,\n",
    "         batch_size,\n",
    "         dataloader,\n",
    "         device,\n",
    "         num_classes = 2):\n",
    "    predictions = np.zeros((128, 3))\n",
    "    for batch_idx, inputs in enumerate(dataloader):\n",
    "        softmaxs = predict_ensemble(main_models, inputs, device, \"sigmoid\")\n",
    "        for image_idx in range(inputs.size(0)):\n",
    "            predictions[batch_idx*batch_size + image_idx, :] = softmaxs[image_idx, :]\n",
    "    return predictions\n",
    "\n",
    "def write_disk(target_root, sample_names, sample_predictions):\n",
    "    for i in range(len(sample_names)):\n",
    "        target_path = os.path.join(target_root, sample_names[i]+\"_detections.npy\")\n",
    "        np.save(target_path, sample_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T10:14:29.425282Z",
     "start_time": "2018-10-09T10:14:29.412354Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.batch_size = 240\n",
    "        self.num_classes = 3\n",
    "        \n",
    "        self.target_h = 224\n",
    "        self.target_w = 224\n",
    "        \n",
    "        self.gpus = \"0,1,2,3\"\n",
    "        self.num_workers = 6\n",
    "\n",
    "config = Config()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T10:15:05.069556Z",
     "start_time": "2018-10-09T10:14:30.472222Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = map(int, config.gpus.split(\",\"))\n",
    "device = torch.device(\"cuda:{}\".format(gpus[0]))\n",
    "\n",
    "model_config = namedtuple(\"Model\", [\"network\", \"checkpoint\", \"net_config\"])\n",
    "\n",
    "model_configs = [\n",
    "    model_config(\"ResNet50_original\", \"checkpoint/multiple_label/ResNet50_original/aug_multipleLabel/epoch102.pth\", None),\n",
    "    model_config(\"DenseNet121_original\", \"checkpoint/multiple_label/DenseNet121_original/aug_multipleLabel/epoch56.pth\", None),\n",
    "    model_config(\"ResNet34_original\", \"checkpoint/multiple_label/ResNet34_original/aug_multipleLabel3/epoch2.pth\", None),\n",
    "    model_config(\"ResNet34_original\", \"checkpoint/multiple_label/ResNet34_original/aug_multipleLabel2/epoch1.pth\", None),\n",
    "    model_config(\"ResNet34_original\", \"checkpoint/multiple_label/ResNet34_original/aug_multipleLabel/epoch0.pth\", None),\n",
    "\n",
    "    model_config(\"ResNet18_original\", \"checkpoint/multiple_label/ResNet18_original/aug_multipleLabel/epoch8.pth\", None),\n",
    "    model_config(\"ResNet18_original\", \"checkpoint/multiple_label/ResNet18_original/aug_multipleLabel2/epoch162.pth\", None),\n",
    "    model_config(\"ResNet18_original\", \"checkpoint/multiple_label/ResNet18_original/aug_multipleLabel3/epoch141.pth\", None),\n",
    "\n",
    "    model_config(\"ResNet50_original\", \"checkpoint/multiple_label/ResNet50_original/aug_multipleLabel2/epoch17.pth\", None),\n",
    "    model_config(\"ResNet34_original\", \"checkpoint/multiple_label/ResNet34_original/aug_multipleLabel4/epoch29.pth\", None),\n",
    "    model_config(\"ResNet34_original\", \"checkpoint/multiple_label/ResNet34_original/aug_multipleLabel5/epoch20.pth\", None),\n",
    "\n",
    "    model_config(\"DenseNet121_original\", \"checkpoint/multiple_label/DenseNet121_original/aug_multipleLabel1/epoch23.pth\", None), #0.9863\n",
    "    model_config(\"DenseNet121_original\", \"checkpoint/multiple_label/DenseNet121_original/aug_multipleLabel2/epoch8.pth\", None), #0.9831\n",
    "    model_config(\"DenseNet121_original\", \"checkpoint/multiple_label/DenseNet121_original/aug_multipleLabel3/epoch72.pth\", None), #0.9811\n",
    "    model_config(\"DenseNet121_original\", \"checkpoint/multiple_label/DenseNet121_original/aug_multipleLabel4/epoch17.pth\", None), #0.9891\n",
    "    model_config(\"DenseNet121_original\", \"checkpoint/multiple_label/DenseNet121_original/aug_multipleLabel5/epoch112.pth\", None), #0.9859\n",
    "    model_config(\"DenseNet121_original\", \"checkpoint/multiple_label/DenseNet121_original/aug_multipleLabel6/epoch11.pth\", None), #0.9814\n",
    "    \n",
    "    model_config(\"DenseNet169_original\", \"checkpoint/multiple_label/DenseNet169_original/aug_multipleLabel/epoch138.pth\", None), #0.9846\n",
    "    model_config(\"DenseNet169_original\", \"checkpoint/multiple_label/DenseNet169_original/aug_multipleLabel1/epoch132.pth\", None), #0.9869\n",
    "    model_config(\"DenseNet169_original\", \"checkpoint/multiple_label/DenseNet169_original/aug_multipleLabel2/epoch42.pth\", None), #0.9863\n",
    "    model_config(\"DenseNet169_original\", \"checkpoint/multiple_label/DenseNet169_original/aug_multipleLabel3/epoch42.pth\", None), #0.9792\n",
    "    model_config(\"DenseNet169_original\", \"checkpoint/multiple_label/DenseNet169_original/aug_multipleLabel4/epoch151.pth\", None), #0.9847\n",
    "    model_config(\"DenseNet169_original\", \"checkpoint/multiple_label/DenseNet169_original/aug_multipleLabel5/epoch164.pth\", None), #0.9813\n",
    "    \n",
    "    model_config(\"DenseNet201_original\", \"checkpoint/multiple_label/DenseNet201_original/aug_multipleLabel/epoch11.pth\", None), \n",
    "    model_config(\"DenseNet201_original\", \"checkpoint/multiple_label/DenseNet201_original/aug_multipleLabel2/epoch21.pth\", None), \n",
    "    \n",
    "    model_config(\"DenseNet201_original\", \"checkpoint/multiple_label/DenseNet201_original/aug_multipleLabel4/epoch78.pth\", None), \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "main_models = [load_model(model_configObj, config.num_classes, device, gpus) for model_configObj in model_configs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T10:17:43.892905Z",
     "start_time": "2018-10-09T10:15:09.175808Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_path = \"./data/Edema_testset/original_images\"\n",
    "sample_predictions, sample_names = [], []\n",
    "for sample_name in tqdm(sorted(os.listdir(root_path))):\n",
    "    sample_names.append(sample_name.replace(\".img\", \"\"))\n",
    "    sample_path = os.path.join(root_path, sample_name)\n",
    "    \n",
    "    dataset = OCT_classification_persample(sample_path, \n",
    "                         transform = transforms.Compose([\n",
    "                             Resize((config.target_h, config.target_w)),\n",
    "                             Normalize_divide(255.0)\n",
    "                         ]))\n",
    "    \n",
    "    dataset_loader = torch.utils.data.DataLoader(dataset, batch_size = config.batch_size,\n",
    "                                             shuffle=False, num_workers=config.num_workers)\n",
    "    predictions = main(main_models, \n",
    "                       config.batch_size,\n",
    "                       dataset_loader,\n",
    "                       device,\n",
    "                       num_classes = config.num_classes)\n",
    "    sample_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-09T10:18:13.705248Z",
     "start_time": "2018-10-09T10:18:13.692103Z"
    }
   },
   "outputs": [],
   "source": [
    "write_disk(\"./predictions/classification/20181009\", sample_names, sample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
