{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T02:47:51.628888Z",
     "start_time": "2018-09-26T02:47:51.520012Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, pdb, cv2, random, traceback, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from pprint import pprint, pformat\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict, namedtuple\n",
    "from sklearn.metrics import  roc_curve, auc\n",
    "\n",
    "from dataloaders.Classification_Image import OCT_image_classification, OCT_classification_persample, natural_keys\n",
    "from dataloaders.Image_transforms import Resize, Split_h, Normalize_divide, To_CHW    \n",
    "from sklearn import metrics\n",
    "\n",
    "from networks.classification.ResNet import ResNet34, ResNet50, ResNet101\n",
    "from networks.classification.ResNet_original import ResNet34_original, ResNet50_original\n",
    "from networks.classification.DenseNet_original import DenseNet121_original\n",
    "\n",
    "from utils import aic_fundus_lesion_classification\n",
    "\n",
    "def save_pickle(obj, save_path): \n",
    "    parent_path = os.path.dirname(save_path)  # get parent path\n",
    "    if not os.path.exists(parent_path):\n",
    "        os.makedirs(parent_path)\n",
    "    cPickle.dump(obj, open(save_path, \"wb\"), True)\n",
    "\n",
    "def load_pickle(pickle_path):\n",
    "    with open(pickle_path, 'rb') as fo:\n",
    "        pickle_dict = cPickle.load(fo)\n",
    "    return pickle_dict\n",
    "\n",
    "def load_model(model_config, num_classes, device, gpus):\n",
    "    model = globals()[model_config.network](model_config.net_config, num_classes)\n",
    "    print(\"Load %s\"%(model_config.checkpoint))\n",
    "    model.load_state_dict(torch.load(model_config.checkpoint))\n",
    "    if len(gpus) > 1:\n",
    "        model = nn.DataParallel(model, gpus)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def get_labels(label_root, label_dict = OrderedDict([(255, 0), (191, 1), (128, 2)]), num_samples=128):\n",
    "    total_labels = []\n",
    "    for label_sample_name in tqdm(sorted(os.listdir(label_root))):\n",
    "        sample_labels = np.zeros((num_samples, 3))\n",
    "        # sort the image dir in numerical ascend order\n",
    "        image_names = os.listdir(os.path.join(label_root, label_sample_name))\n",
    "        image_names.sort(key=natural_keys)\n",
    "        for i, image_name in enumerate(image_names):\n",
    "            label_image = cv2.imread(os.path.join(label_root, label_sample_name, image_name))[:,:,0]\n",
    "            for target_pixel in label_dict:\n",
    "                if target_pixel in label_image:\n",
    "                    sample_labels[i, label_dict[target_pixel]] = 1\n",
    "        total_labels.append(sample_labels)\n",
    "    return total_labels\n",
    "\n",
    "def predict_ensemble(models, inputs, device):\n",
    "    \"\"\"predict single input from the data loader via multiple models\"\"\"\n",
    "    with torch.no_grad():\n",
    "        inputs = inputs.float()\n",
    "        inputs = inputs.to(device)\n",
    "        softmaxs = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            output = model(inputs)\n",
    "            softmax = F.softmax(output, dim=1).detach().cpu().numpy()\n",
    "            softmaxs.append(softmax)\n",
    "        ensemble = np.mean(softmaxs, 0)\n",
    "    return ensemble\n",
    "\n",
    "def main(normal_edemas_models, edema_PEDs_models, edema_SRFs_models,\n",
    "         batch_size,\n",
    "         dataloader,\n",
    "         device,\n",
    "         num_classes = 2):\n",
    "    predictions = np.zeros((128, 3))\n",
    "    for batch_idx, inputs in enumerate(dataloader):\n",
    "        edema_softmax = predict_ensemble(normal_edemas_models, inputs, device)\n",
    "        PED_softmax = predict_ensemble(edema_PEDs_models, inputs, device)\n",
    "        SRF_softmax = predict_ensemble(edema_SRFs_models, inputs, device)\n",
    "        for image_idx in range(inputs.size(0)):\n",
    "            predictions[batch_idx*batch_size + image_idx, 0] = edema_softmax[image_idx, 1]\n",
    "            predictions[batch_idx*batch_size + image_idx, 1] = SRF_softmax[image_idx, 1]\n",
    "            predictions[batch_idx*batch_size + image_idx, 2] = PED_softmax[image_idx, 1]\n",
    "    return predictions\n",
    "\n",
    "def write_disk(target_root, sample_names, sample_predictions):\n",
    "    for i in range(len(sample_names)):\n",
    "        target_path = os.path.join(target_root, sample_names[i]+\"_detections.npy\")\n",
    "        np.save(target_path, sample_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T02:01:22.169521Z",
     "start_time": "2018-09-26T02:01:22.155223Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.batch_size = 60\n",
    "        self.num_classes = 2\n",
    "        self.num_split = 2\n",
    "        \n",
    "        self.target_h = 224\n",
    "        self.target_w = 224\n",
    "        \n",
    "        self.gpus = \"0, 3\"\n",
    "        self.num_workers = 4\n",
    "\n",
    "config = Config()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T02:01:36.391809Z",
     "start_time": "2018-09-26T02:01:22.768668Z"
    }
   },
   "outputs": [],
   "source": [
    "gpus = map(int, config.gpus.split(\",\"))\n",
    "device = torch.device(\"cuda:{}\".format(gpus[0]))\n",
    "resnet_config = {\"ensemble_idx\": 7, \"feature_size\": 7}\n",
    "\n",
    "model_config = namedtuple(\"Model\", [\"network\", \"checkpoint\", \"net_config\"])\n",
    "\n",
    "# train\n",
    "# normal/edemas\n",
    "# model_config(\"ResNet34_original\", \"checkpoint/normal_edema/ResNet34_original/aug/epoch23.pth\", None), AUC 0.9907\n",
    "# model_config(\"ResNet50_original\", \"checkpoint/normal_edema/ResNet50_original/aug/epoch89.pth\", None), epoch 89 AUC 0.9864, epoch 70 AUC 0.9861\n",
    "# model_config(\"DenseNet121_original\", \"checkpoint/normal_edema/DenseNet121_original/aug/epoch41.pth\", None), epoch 41 AUC 0.9869, epoch 56 0.9848\n",
    "# model_config(\"DenseNet121_original\", \"checkpoint/normal_edema/DenseNet121_original/aug_20180924_150746/epoch88.pth\", None) AUC 0.9831\n",
    "\n",
    "# used, AUC 0.9912 \n",
    "# model_config(\"ResNet34_original\", \"checkpoint/normal_edema/ResNet34_original/aug/epoch23.pth\", None),\n",
    "# model_config(\"ResNet50_original\", \"checkpoint/normal_edema/ResNet50_original/aug/epoch89.pth\", None),\n",
    "# model_config(\"DenseNet121_original\", \"checkpoint/normal_edema/DenseNet121_original/aug/epoch41.pth\", None)\n",
    "\n",
    "# edema_SRFs, AUC 0.9913\n",
    "# model_config(\"ResNet34_original\", \"checkpoint/edema_SRF/ResNet34_original/aug_oversample_includeNormal/epoch19.pth\", None)\n",
    "# model_config(\"ResNet50_original\", \"checkpoint/edema_SRF/ResNet50_original/aug_includeNormal/epoch7.pth\", None)\n",
    "\n",
    "# PED\n",
    "# model_config(\"ResNet50_original\", \"checkpoint/edema_PED/ResNet50_original/aug_oversample_includeNormal/epoch15.pth\", None), AUC 0.9913\n",
    "# model_config(\"ResNet50_original\", \"checkpoint/edema_PED/ResNet50_original/aug_oversample_includeNormal_20180924_150856/epoch65.pth\", None), AUC 0.9924\n",
    "\n",
    "# model_config(\"DenseNet121_original\", \"checkpoint/edema_PED/DenseNet121_original/aug_oversample_includeNormal/epoch13.pth\", None), epoch 13 AUC 0.9924, epoch 16 AUC 0.9924\n",
    "# model_config(\"DenseNet121_original\", \"checkpoint/edema_PED/DenseNet121_original/aug_oversample_includeNormal_20180924_150921/epoch67.pth\", None),  AUC 0.9915\n",
    "\n",
    "# desired, checkpoint/normal_edema/ResNet50_original/aug/epoch70.pth\n",
    "normal_edemas = [\n",
    "                model_config(\"ResNet34_original\", \"checkpoint/normal_edema/ResNet34_original/aug/epoch23.pth\", None)\n",
    "#                  model_config(\"ResNet50_original\", \"checkpoint/normal_edema/ResNet50_original/aug/epoch70.pth\", None),\n",
    "#                  model_config(\"DenseNet121_original\", \"checkpoint/normal_edema/DenseNet121_original/aug/epoch41.pth\", None)\n",
    "                ]\n",
    "\n",
    "edema_SRFs = [\n",
    "    model_config(\"ResNet50_original\", \"checkpoint/edema_SRF/ResNet50_original/aug_includeNormal/epoch7.pth\", None)\n",
    "#              model_config(\"ResNet34_original\", \"checkpoint/edema_SRF/ResNet34_original/aug_oversample_includeNormal/epoch19.pth\", None),\n",
    "#              model_config(\"ResNet50_original\", \"checkpoint/edema_SRF/ResNet50_original/aug_includeNormal/epoch7.pth\", None)\n",
    "            ]\n",
    "\n",
    "edema_PEDs = [\n",
    "    model_config(\"ResNet50_original\", \"checkpoint/edema_PED/ResNet50_original/aug_oversample_includeNormal/epoch15.pth\", None),\n",
    "#                 model_config(\"ResNet50_original\", \"checkpoint/edema_PED/ResNet50_original/aug_oversample_includeNormal_20180924_150856/epoch54.pth\", None),\n",
    "#                 model_config(\"DenseNet121_original\", \"checkpoint/edema_PED/DenseNet121_original/aug_oversample_includeNormal/epoch13.pth\", None),\n",
    "#                 model_config(\"DenseNet121_original\", \"checkpoint/edema_PED/DenseNet121_original/aug_oversample_includeNormal_20180924_150921/epoch67.pth\", None)\n",
    "              ]\n",
    "\n",
    "normal_edemas_models = [load_model(normal_edema, config.num_classes, device, gpus) for normal_edema in normal_edemas]\n",
    "edema_SRFs_models = [load_model(edema_SRF, config.num_classes, device, gpus) for edema_SRF in edema_SRFs]\n",
    "edema_PEDs_models = [load_model(edema_PED, config.num_classes, device, gpus) for edema_PED in edema_PEDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T02:02:09.786734Z",
     "start_time": "2018-09-26T02:01:36.396234Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root_path = \"./data/Edema_validationset/original_images\"\n",
    "sample_predictions, sample_names = [], []\n",
    "for sample_name in tqdm(sorted(os.listdir(root_path))):\n",
    "    sample_names.append(sample_name.replace(\".img\", \"\"))\n",
    "    sample_path = os.path.join(root_path, sample_name)\n",
    "    \n",
    "    dataset = OCT_classification_persample(sample_path, \n",
    "                         transform = transforms.Compose([\n",
    "                             Resize((config.target_h, config.target_w)),\n",
    "                             Normalize_divide(255.0)\n",
    "                         ]))\n",
    "\n",
    "    dataset_loader = torch.utils.data.DataLoader(dataset, batch_size = config.batch_size,\n",
    "                                             shuffle=False, num_workers=config.num_workers)\n",
    "    predictions = main(normal_edemas_models, edema_PEDs_models, edema_SRFs_models, \n",
    "                       config.batch_size,\n",
    "                       dataset_loader,\n",
    "                       device,\n",
    "                       num_classes = config.num_classes)\n",
    "    sample_predictions.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T13:43:23.029836Z",
     "start_time": "2018-09-25T13:43:23.015985Z"
    }
   },
   "outputs": [],
   "source": [
    "# for sample_prediction in sample_predictions:\n",
    "#     for i in range(128):\n",
    "#         if sample_prediction[i][0] < 0.5 and sample_prediction[i][2] > 0.5:\n",
    "#             print(sample_prediction[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T14:21:00.051304Z",
     "start_time": "2018-09-25T14:21:00.035080Z"
    }
   },
   "outputs": [],
   "source": [
    "# write_disk(\"./predictions/classification/test/lisijia/20180925_3\", sample_names, sample_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T02:02:18.959247Z",
     "start_time": "2018-09-26T02:02:15.042684Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vallabel_root = \"./data/Edema_validationset/label_images\"\n",
    "valsample_labels = get_labels(vallabel_root)\n",
    "valsample_aucs = [aic_fundus_lesion_classification(valsample_labels[i], sample_predictions[i]) for i in range(len(sample_predictions))]\n",
    "valid_aucs = []\n",
    "for sample_auc in valsample_aucs:\n",
    "    for auc_value in sample_auc:\n",
    "        if math.isnan(auc_value): continue\n",
    "        valid_aucs.append(auc_value)\n",
    "pprint(valsample_aucs)\n",
    "print(\"mean auc: %.4f\"%(np.mean(valid_aucs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-26T02:02:22.871128Z",
     "start_time": "2018-09-26T02:02:22.860251Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "valid_aucs = [[], [], []]\n",
    "for sample_auc in valsample_aucs:\n",
    "    for i, auc_value in enumerate(sample_auc):\n",
    "        if not math.isnan(auc_value):\n",
    "            valid_aucs[i].append(auc_value)\n",
    "for auc_values in valid_aucs:\n",
    "    print(np.mean(auc_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T11:50:04.707077Z",
     "start_time": "2018-09-25T11:50:04.696312Z"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(valid_aucs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
